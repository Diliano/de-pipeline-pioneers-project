# Data Engineering Bootcamp - Group Project

## About This Project

This project was created as part of our Data Engineering Bootcamp. It reflects our collective efforts to design and implement a data pipeline with ingestion, transformation, and loading stages, along with a visualisation component.

## Learning

The goal of the project was to journey as a collective, providing everyone an opportunity to take our learnings from the bootcamp and apply them to a group project.

Although we were a few steps away from reaching our base goal, I learned an incredible amount in a short space of time. 

**Technical Takeaways:**

- I explored Infrastructure as Code, building Terraform resources for our data pipeline.
- I created multiple diagrams, including: 
    - A project overview for our first planning meeting.
    - A detailed transformation diagram to highlight tasks such as column renaming, data type conversions and table joins.
- I planned and implemented the loading stage using a Test-Driven approach, achieving 100% test coverage across unit and integration tests.

**Collaboration Takeaways:**

- Participated in Agile operations such as daily stand-ups (including leading them!), Kanban boards, sprint planning, sprint delivery and retrospectives.
- Conducted collaborative code reviews.
- Leveraged Git and Github effectively:
    - Developed a branching strategy.
    - Created and worked on separate branches, merging at regular checkpoints.
- Embraced the journey as much as the destination, valuing the opportunity to collaborate with a larger group for the first time in the Bootcamp. This experience helped me build essential skills to contribute effectively in future teams.

## Final State of the Project

This version represents the final state of the project as a team effort. It preserves the work completed up to the project deadline and reflects the collaborative contributions of all team members. 

## Next Steps

As I have preserved the final state of the group project, this repository will not be actively developed further. If we had more time to continue development as a team, our priorities would have included:

- Finalising the data pipeline and completing the remaining connections.
- Expanding the data warehouse to include additional fact and dimension tables.
- Improving the robustness of the pipeline by implementing retry mechanisms.
- Incorporating new data points and data sources to enhance the ingestion stage (e.g. currency API data).